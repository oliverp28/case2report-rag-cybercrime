{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6a2427",
   "metadata": {},
   "source": [
    "# Create Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08465325-d069-4a47-b349-81639085a668",
   "metadata": {},
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "d833cd93-e80c-45e0-a536-457de9cd60e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# System modules\n",
    "import os\n",
    "\n",
    "# json structure\n",
    "import json\n",
    "\n",
    "# Keyword Extraction Functions\n",
    "import re\n",
    "\n",
    "# Neo4j integration\n",
    "import neo4j\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "# OpenAI integration\n",
    "import openai\n",
    "\n",
    "# pandas functionalities\n",
    "import pandas as pd\n",
    "\n",
    "# LangChain functionalities\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "# Langfuse integration\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc28a63-dc43-4fe3-86a4-e37ebd4f7bfa",
   "metadata": {},
   "source": [
    "## Create Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f03d93-c65a-4230-a164-4e8719cee5b7",
   "metadata": {},
   "source": [
    "### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdb9a5-fffb-40c0-b1a7-22acbf1eb08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_key = \"your_key\"\n",
    "neo4j_username = \"your_username\"\n",
    "neo4j_password = \"your_password\"\n",
    "neo4j_uri = \"bolt://localhost:7687\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8cda0e-2ae2-4448-94b3-8666f04724b3",
   "metadata": {},
   "source": [
    "### GPT-4o API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1a8c3e-71d4-422e-9022-8b3060728639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = llm_key\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a84f6c-c43c-4e91-9eaa-fe91062d8833",
   "metadata": {},
   "source": [
    "### Neo4j API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce9568-ed5b-4aa1-b708-9aad8f2bd4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = neo4j_uri\n",
    "os.environ[\"NEO4J_USERNAME\"] = neo4j_username\n",
    "os.environ[\"NEO4J_PASSWORD\"] = neo4j_password\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc48f09-173a-4a4f-bba7-7be4236d269c",
   "metadata": {},
   "source": [
    "## Langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833d4be-78c0-4db8-9b76-fe081de132e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=\"your_public_key\",\n",
    "    secret_key=\"your_secret_key\",\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50f909-b8a5-452d-97e9-900e06037766",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf279154-5ada-44fd-a839-d0025b90b158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_pdf(pdf_file):\n",
    "    \"\"\"\n",
    "    Processes a PDF file, extracts its content, and prints the first three pages.\n",
    "    \n",
    "    Parameters:\n",
    "        pdf_file (str): The path to the PDF file.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of Document objects representing the content of the PDF.\n",
    "    \"\"\"\n",
    "    # Load and split the PDF\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    documents = loader.load_and_split()\n",
    "    \n",
    "    # Print the first three documents for preview\n",
    "    for doc in documents[:3]:\n",
    "        print(f\"Page: {doc.metadata['page']}\\nContent: {doc.page_content[:200]}...\\n\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f533d-7c51-47af-9def-80b6f71d6594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_path = \"KG_Datensatz.pdf\"\n",
    "documents = process_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148c3f3-c50e-400b-8f50-24876ff62c86",
   "metadata": {},
   "source": [
    "### Construction of the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270a110-a779-43dd-807c-85c10febc3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd536246-b6b3-4c5d-8dec-9610cc015bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for node in graph_documents[0].nodes[:5]:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de177d-37ba-4c21-a202-f036b47620aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for relationship in graph_documents[0].relationships[:5]:\n",
    "    print(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735b48e-5c8b-4d73-ad4f-fbfbef8e954a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca2985-26ba-4d30-a755-57daff016507",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b8625-5c3a-4ed1-851a-beffe5f1d463",
   "metadata": {},
   "source": [
    "### Load cybercrime cases from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "98b7bc08-9279-4d30-986d-ce74f3c95200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompts_from_csv(file_path: str, prompt_text: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and generates prompts based on the data.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        prompt_text (str): Instruction text to prepend to each prompt.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of formatted prompts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Define the prompt template\n",
    "    prompt_template = \"\"\"{instruction}\\n\\nData and Time: {date_time};\\nLocation: {location};\\nIncident Description: {incident_description};\\nInformation on Suspects or Witnesses: {suspect_info};\\nDamage(€): {damage};\"\"\"\n",
    "    \n",
    "    # Generate prompts\n",
    "    prompts = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = prompt_template.format(\n",
    "            instruction=prompt_text,\n",
    "            date_time=row[\"Date and Time\"],\n",
    "            location=row[\"Location\"],\n",
    "            incident_description=row[\"Incident Description\"],\n",
    "            suspect_info=row[\"Information on Suspects or Witnesses\"],\n",
    "            damage=row[\"Damage (€)\"],\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892eddd0-7924-490d-b374-a4696e2eeaff",
   "metadata": {},
   "source": [
    "### Cybercrime Case Pre-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "d65aed74-79e4-4f85-891f-405221a4c7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_analysis_prompt_text = \"\"\"\n",
    "Answer the following questions briefly and precisely:\n",
    "\n",
    "Task:\n",
    "1. What \"Cybercrime Phenomenon\" is present in the given case?\n",
    "2. What \"Investigation measures\" are appropriate?\n",
    "\n",
    "Provide your answer in the following format and spelling:\n",
    "- Cybercrime Phenomenon: \"Phenomenon\"\n",
    "\n",
    "- Investigation measures: \"measure1, measure2, ...\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "561d24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_analysis_context = \"\"\"\n",
    "This case describes a cybercrime incident from the perspective of an affected individual. \n",
    "It provides details about the event, including the circumstances, \n",
    "potential threats, and any available information about suspects or damages. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "e84fb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_analysis_system_message = \"\"\"\n",
    "As a cybercrime investigation expert, \n",
    "you assist law enforcement in analyzing cases by identifying cybercrime phenomena and \n",
    "investigative methods. These methods should be presented \n",
    "as keywords, such as \"Email Analysis\" or \"Domain Analysis,\" without full sentences.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "78183aed-b899-4f51-8b2d-813fadffc0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_analysis_prompts = create_prompts_from_csv(file_path, baseline_analysis_prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "02742ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the following questions briefly and precisely:\n",
      "\n",
      "Task:\n",
      "1. What \"Cybercrime Phenomenon\" is present in the given case?\n",
      "2. What \"Investigation measures\" are appropriate?\n",
      "\n",
      "Provide your answer in the following format and spelling:\n",
      "- Cybercrime Phenomenon: \"Phenomenon\"\n",
      "\n",
      "- Investigation measures: \"measure1, measure2, ...\"\n",
      "\n",
      "\n",
      "Data and Time: 2025-02-28 21:10;\n",
      "Location: Online;\n",
      "Incident Description: I was searching for a free streaming app on my Smart TV and found a site that offered a download link. After installation, my TV restarted, and a message appeared on the screen: 'Your device has been locked! Pay €300 in Bitcoin to unlock it.' I could no longer use any functions, and even resetting the device did not work. The TV manufacturer's support confirmed that this was ransomware and advised me not to pay.;\n",
      "Information on Suspects or Witnesses: The app was downloaded from a website called 'best-streaming-apps.com'.;\n",
      "Damage(€): 300;\n"
     ]
    }
   ],
   "source": [
    "print(baseline_analysis_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a2b3fe",
   "metadata": {},
   "source": [
    "### OpenAI Pre-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "b06ee661-880c-44d2-a3b4-0d727d4743e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyse_cybercrime_prompt(api_key: str, prompt: str, context: str, system_message: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes a given cybercrime prompt and determines the relevant cybercrime phenomenon \n",
    "    as well as appropriate police investigation measures in the context of initial assessment.\n",
    "    \n",
    "    :param api_key: Your OpenAI API key\n",
    "    :param prompt: The input text describing a cybercrime situation\n",
    "    :return: The analysis and recommended police measures as a string\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"chatgpt-4o-latest\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": context}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "cb6f6a43-eff4-4637-a38c-cc7784cad170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_cybercrime_details(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the cybercrime phenomenon and recommended investigation measures from the input string.\n",
    "    \n",
    "    :param output: The raw response containing cybercrime details.\n",
    "    :return: A dictionary containing the identified phenomenon and recommended investigation measures.\n",
    "    \"\"\"\n",
    "    identified_phenomenon = None\n",
    "    recommended_investigation_measures = None\n",
    "\n",
    "    phenomenon_match = re.search(r'(?:\\*\\*)?\\s*cybercrime\\s*phenomenon\\s*:\\s*\"(.*?)\"', output, re.IGNORECASE)\n",
    "    measures_match = re.search(r'(?:\\*\\*)?\\s*investigation\\s*measures\\s*:\\s*\"(.*?)\"', output, re.IGNORECASE)\n",
    "\n",
    "    if phenomenon_match:\n",
    "        identified_phenomenon = phenomenon_match.group(1)\n",
    "    if measures_match:\n",
    "        recommended_investigation_measures = measures_match.group(1)\n",
    "\n",
    "    return {\n",
    "        \"identified_phenomenon\": identified_phenomenon,\n",
    "        \"recommended_investigation_measures\": recommended_investigation_measures\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7167f",
   "metadata": {},
   "source": [
    "### Generate Cypher Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "f97971f2-6d0e-49cf-a7a5-eda73182855f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cypher_query(phenomenon, measures, llm_key):\n",
    "    return f\"\"\"\n",
    "CALL apoc.ml.openai.embedding(\n",
    "[\"{phenomenon}\"],\n",
    "\"{llm_key}\"\n",
    ")\n",
    "YIELD index, text AS search_text, embedding\n",
    "MATCH (p:Phenomenon)\n",
    "WHERE p.embedding IS NOT NULL\n",
    "WITH p, gds.similarity.cosine(p.embedding, embedding) AS score\n",
    "ORDER BY score DESC\n",
    "LIMIT 1\n",
    "MATCH (c {{id: \"Cybercrime\"}})-[:INCLUDES_PHENOMENON]->(p)\n",
    "MATCH (c)-[:HAS_CATEGORY]->(category:Category)\n",
    "MATCH (category)\n",
    "CALL apoc.path.subgraphAll(category, {{\n",
    "relationshipFilter: \">\",\n",
    "minLevel: 1,\n",
    "maxLevel: 3\n",
    "}}) YIELD nodes AS category_nodes\n",
    "MATCH (p)\n",
    "CALL apoc.path.subgraphAll(p, {{\n",
    "relationshipFilter: \">\",\n",
    "minLevel: 1,\n",
    "maxLevel: 5\n",
    "}}) YIELD nodes AS phenomenon_nodes, relationships AS phenomenon_relationships\n",
    "MATCH (i {{id: \"Investigation\"}})-[:CONTAINS]->(q {{id: \"Investigation Questions\"}})\n",
    "MATCH (q)-[:INCLUDES]->(question:Question)\n",
    "WITH p, c, category, phenomenon_nodes, phenomenon_relationships, category_nodes, i, q, COLLECT(question) AS investigation_questions\n",
    "\n",
    "CALL apoc.ml.openai.embedding(\n",
    "[\"{measures}\"],\n",
    "\"{llm_key}\"\n",
    ")\n",
    "YIELD index AS investigation_index, text AS investigation_search_text, embedding AS investigation_embedding\n",
    "MATCH (m:Investigation_method)\n",
    "WHERE m.embedding IS NOT NULL\n",
    "WITH p, c, category, phenomenon_nodes, phenomenon_relationships, category_nodes, i, q, investigation_questions,\n",
    "m, gds.similarity.cosine(m.embedding, investigation_embedding) AS investigation_score\n",
    "WITH p, c, category, phenomenon_nodes, phenomenon_relationships, category_nodes, i, q, investigation_questions,\n",
    "CASE WHEN investigation_score > 0.80 THEN m ELSE NULL END AS filtered_m,\n",
    "CASE WHEN investigation_score > 0.80 THEN investigation_score ELSE NULL END AS filtered_score\n",
    "OPTIONAL MATCH (filtered_m)\n",
    "CALL apoc.path.subgraphAll(filtered_m, {{\n",
    "relationshipFilter: \">\",\n",
    "minLevel: 1,\n",
    "maxLevel: 5\n",
    "}})\n",
    "YIELD nodes AS investigation_method_nodes\n",
    "\n",
    "RETURN DISTINCT\n",
    "    apoc.convert.toJson(p) AS Identified_Phenomenon,\n",
    "    apoc.convert.toJson(c) AS Related_Cybercrime,\n",
    "    apoc.convert.toJson(category) AS Cybercrime_Category,\n",
    "    apoc.convert.toJson(phenomenon_nodes) AS Phenomenon_Connected_Nodes,\n",
    "    apoc.convert.toJson(phenomenon_relationships) AS Phenomenon_Connections,\n",
    "    apoc.convert.toJson(category_nodes) AS Cybercrime_Category_Details_Nodes,\n",
    "    apoc.convert.toJson(i) AS Investigation_Node,\n",
    "    apoc.convert.toJson(q) AS Investigation_Questions_Node,\n",
    "    apoc.convert.toJson(investigation_questions) AS Investigation_Questions,\n",
    "    apoc.convert.toJson(COALESCE(COLLECT(filtered_m), [])) AS Most_Similar_Investigation_Methods,\n",
    "    apoc.convert.toJson(COALESCE(COLLECT(investigation_method_nodes), [])) AS Investigation_Method_Details;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "66fe5e65-456c-43c6-85c2-3c4f66455dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_cypher_query(query: str):\n",
    "    \"\"\"\n",
    "    Executes a given Cypher query on a local Neo4j Knowledge Graph and returns the results.\n",
    "    \n",
    "    :param query: The Cypher query to execute\n",
    "    :return: The query result as a list of dictionaries\n",
    "    \"\"\"\n",
    "    driver = GraphDatabase.driver(\n",
    "        os.environ[\"NEO4J_URI\"],\n",
    "        auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            \n",
    "            # Stores all records as a list of dictionaries\n",
    "            records = [record.data() for record in result]\n",
    "            \n",
    "            return records  # Returns the data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None  # Returns None in case of an error\n",
    "\n",
    "    finally:\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d820e",
   "metadata": {},
   "source": [
    "### Format the retrieved information from the Neo4j Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "ae344911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_embedding(data):\n",
    "    \"\"\"\n",
    "    Recursive function that removes all 'embedding' keys from a JSON dictionary or a list.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: remove_embedding(v) for k, v in data.items() if k != \"embedding\"}\n",
    "    elif isinstance(data, list):\n",
    "        return [remove_embedding(item) for item in data]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "c690f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_neo4j_response(neo4j_output):\n",
    "    \"\"\"\n",
    "    Cleans the Neo4j response, removes string embeddings from JSON objects,\n",
    "    eliminates the 'embedding' field, and converts everything into a valid JSON format.\n",
    "\n",
    "    :param neo4j_output: List of Neo4j data as dictionaries\n",
    "    :return: JSON-formatted string without 'embedding' entries\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "\n",
    "    for record in neo4j_output:\n",
    "        cleaned_record = {}\n",
    "        for key, value in record.items():\n",
    "            try:\n",
    "                # If the value is an embedded JSON string, decode it\n",
    "                cleaned_value = json.loads(value)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # If the value is already in a valid format, use it as is\n",
    "                cleaned_value = value\n",
    "\n",
    "            # Remove 'embedding' from the JSON data\n",
    "            cleaned_record[key] = remove_embedding(cleaned_value)\n",
    "\n",
    "        cleaned_data.append(cleaned_record)\n",
    "\n",
    "    return json.dumps({\"Query\": cleaned_data}, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227a95b",
   "metadata": {},
   "source": [
    "## Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "88bd2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_prompt_text = \"\"\"\n",
    "Create a structured police investigation report with a length of 150 words for the given cybercrime case, \n",
    "utilizing information from a Knowledge Graph in JSON format.\n",
    "\n",
    "Important Information:\n",
    "- Use full sentences and detailed explanations.\n",
    "- Clearly structure the report with the following sections and headings.\n",
    "- You are only allowed to use information provided by the structured JSON\n",
    "\n",
    "REPORT STRUCTURE:\n",
    "1. Case Categorization  \n",
    "   - Classify the case as either \"Cybercrime in the narrow sense\" or \"Cybercrime in the broad sense\".  \n",
    "   - Justify your classification with relevant definitions.\n",
    "\n",
    "2. Phenomenon Analysis  \n",
    "   - Identify the specific cybercrime type(s) involved.  \n",
    "   - Explain how this technique works in general (e.g., How phishing attacks operate, technical aspects).\n",
    "\n",
    "3. Legal Assessment  \n",
    "   - Identify which German laws (StGB, BDSG, UrhG) apply.  \n",
    "   - Cite specific paragraphs and explain why they are relevant.  \n",
    "\n",
    "4. Investigation Strategy  \n",
    "   - List concrete forensic measures (e.g., E-Mail Header analysis, specific investigation questions).  \n",
    "   - Provide step-by-step descriptions of how each measure is conducted.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "4bf861cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_prompts = create_prompts_from_csv(file_path, report_prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "49d697a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_context = \"\"\"\n",
    "You are a cybercrime investigation assistant supporting law enforcement with a Neo4j Knowledge Graph.\n",
    "The structured JSON contains the extracted knowledge, serving as the basis for analyzing the case.\n",
    "Your task is to utilize all relevant details to provide a clear and concise assessment.\n",
    "\n",
    "Key Requirements:\n",
    "- Use only data from the JSON.\n",
    "\n",
    "Use this context to enhance the accuracy and detail of your response.    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "e20de067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_in_system_message(json_output):\n",
    "\n",
    "    return f\"You are extracting information from the Knowledge Graph, where the structured JSON provides the necessary knowledge for analyzing the given cybercrime case.\\n\\n{json_output}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100cbfa",
   "metadata": {},
   "source": [
    "### RAG Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "fcb50d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cybercrime_cases_sequentially(baseline_prompts, baseline_context, baseline_system_message, llm_key, report_prompts, report_context):\n",
    "    \"\"\"\n",
    "    Sequentially processes each cybercrime case prompt by executing a series of analysis functions \n",
    "    and stores the results in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        baseline_prompts (list): List of baseline cybercrime case prompts.\n",
    "        baseline_context (str): Context for the baseline analysis.\n",
    "        baseline_system_message (str): System message for baseline analysis.\n",
    "        llm_key (str): API key for the LLM analysis.\n",
    "        phenomenon (str): Cybercrime phenomenon being analyzed.\n",
    "        measures (str): Cybercrime measures being considered.\n",
    "        report_prompts (list): List of report prompts corresponding to each baseline prompt.\n",
    "        report_context (str): Context for the report analysis.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each prompt index to the corresponding result.\n",
    "    \"\"\"\n",
    "    rag_results = {}\n",
    "\n",
    "    # Ensure the lists have the same length\n",
    "    if len(baseline_prompts) != len(report_prompts):\n",
    "        raise ValueError(\"baseline_prompts and report_prompts must have the same length\")\n",
    "\n",
    "    # Iterate through each prompt pair with an index\n",
    "    for index, (baseline_prompt, report_prompt) in enumerate(zip(baseline_prompts, report_prompts), start=1):\n",
    "        print(f\"Processing case {index}/{len(baseline_prompts)}: {baseline_prompt}\")\n",
    "\n",
    "        # Step 1: Generate the LLM response based on the baseline prompt\n",
    "        baseline_cybercrime_llm_response = analyse_cybercrime_prompt(llm_key, baseline_prompt, baseline_context, baseline_system_message)\n",
    "\n",
    "        # Step 2: Extract relevant cybercrime details\n",
    "        baseline_cybercrime_details = extract_cybercrime_details(baseline_cybercrime_llm_response)\n",
    "        \n",
    "        phenomenon = baseline_cybercrime_details[\"identified_phenomenon\"]\n",
    "        measures = baseline_cybercrime_details[\"recommended_investigation_measures\"]\n",
    "\n",
    "        # Step 3: Generate the Cypher query using extracted details\n",
    "        cybercrime_cypher_query = generate_cypher_query(phenomenon, measures, llm_key)\n",
    "\n",
    "        # Step 4: Execute the generated Cypher query to retrieve information\n",
    "        cybercrime_informations = execute_cypher_query(cybercrime_cypher_query)\n",
    "\n",
    "        # Step 5: Format the retrieved Neo4j response into JSON\n",
    "        json_output = format_neo4j_response(cybercrime_informations)\n",
    "        \n",
    "        # Step 6: Update system message with JSON output\n",
    "        report_system_message = update_json_in_system_message(json_output)\n",
    "        \n",
    "        # Step 7: Generate the LLM response based on the report prompt\n",
    "        cybercrime_report = analyse_cybercrime_prompt(llm_key, report_prompt, report_context, report_system_message)\n",
    "\n",
    "        # Save the result indexed by the prompt number\n",
    "        rag_results[index] = {\n",
    "            \"report_prompt\": report_prompt,\n",
    "            \"cypher_query\": cybercrime_cypher_query,\n",
    "            \"formatted_json\": json_output,\n",
    "            \"cybercrime_report\": cybercrime_report\n",
    "        }\n",
    "\n",
    "        # Optional: Print progress\n",
    "        print(f\"Finished processing case {index}\\n\")\n",
    "\n",
    "    return rag_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44164e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_results = process_cybercrime_cases_sequentially(baseline_analysis_prompts, baseline_analysis_context, baseline_analysis_system_message, llm_key, report_prompts, report_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
